# =============================================================================
# SNEMI3D + CREMI3D Combined Vista3D Configuration
# =============================================================================
# Training Vista3D model on combined SNEMI3D and CREMI3D datasets for
# multi-class neuron segmentation in electron microscopy images.
#
# Dataset formats (instance segmentation challenge format):
# - 'image': input EM volume [Z, Y, X]
# - 'label': indexed instance segmentation (unique IDs per object)
# - 'class_ids': semantic class for each pixel (background=0, neuron=1, ...)
#
# SNEMI3D: Single class (neuron) - [100, 1024, 1024] @ 6nm/px XY, 30nm/slice Z
# CREMI3D: Multiple classes (neuron, cleft, mito) - [125, 1250, 1250] @ 4nm/px
#
# Usage:
#   python scripts/train_vista3d.py --config configs/snemi3d_cremi3d.yaml
# =============================================================================

# Experiment settings
experiment_name: snemi3d_cremi3d
project_name: neurocircuitry-vista3d
seed: 42
logger: tensorboard
log_dir: logs

# =============================================================================
# Data Configuration
# =============================================================================
data:
  # Multi-dataset mode: combines SNEMI3D and CREMI3D
  dataset: multi
  
  # Dataset-specific configurations
  datasets:
    snemi3d:
      enabled: true
      data_root: data/SNEMI3D
      weight: 1.0  # Sampling weight relative to other datasets
      
    cremi3d:
      enabled: true
      data_root: data/CREMI3D
      weight: 1.0
      # CREMI volumes to use (only A available currently)
      volumes: ["A"]
  
  # 3D patch size for training [Z, Y, X]
  # Using [32, 128, 128] for compatibility with both datasets
  # SNEMI3D: 100 Z slices, CREMI3D: 125 Z slices
  patch_size: [32, 128, 128]
  
  # Batch size (reduce if OOM)
  batch_size: 4
  
  # Data loading
  num_workers: 4
  cache_rate: 1.0  # Cache full volumes in memory
  
  # Virtual expansion factor for sampling many patches from few volumes
  # With 1 volume per dataset, this creates (2 volumes * factor) samples per epoch
  train_expansion_factor: 100  # 200 total train samples (with random crop augmentation)
  val_expansion_factor: 10     # 20 total val samples
  
  # Train/validation split ratio
  train_val_split: 0.2
  
  # Data augmentation
  augmentation: true
  
  # Unified semantic class configuration for both datasets
  semantic_classes:
    # Class names (index = class_id)
    # 0=background, 1=neuron, 2=cleft, 3=mito
    names: ["background", "neuron", "cleft", "mito"]
    
    # Per-dataset instance ID to class mapping
    per_dataset:
      snemi3d:
        # SNEMI3D: all foreground is neuron (class 1)
        instance_ids: null  # null = use default_class for all foreground
        default_class: 1
        
      cremi3d:
        # CREMI3D: has separate annotations for each structure
        # Instance IDs are assigned based on annotation type during loading
        instance_ids: null  # Handled by CREMI3D dataset loader
        default_class: 1    # Default to neuron if unmapped
    
    # Global default for unmapped foreground
    default_class: 1

# =============================================================================
# Model Configuration
# =============================================================================
model:
  # Architecture
  encoder_name: segresnet  # 'segresnet' or 'swin'
  feature_size: 48
  
  # Input/Output
  in_channels: 1
  # NOTE: num_classes is auto-derived from data.semantic_classes.names
  # This is overridden at runtime by the training script
  # num_classes: 4  # 0=background, 1=neuron, 2=cleft, 3=mito
  
  # Semantic and Instance heads (following ariel architecture)
  sem_head: 16  # Semantic embedding dimension
  ins_head: 16  # Instance embedding dimension
  use_sem_head: true  # Enable semantic head (conv layers after base model)
  use_ins_head: true  # Enable instance embedding for discriminative loss
  
  # Pretrained weights
  pretrained: false  # Set true to load MONAI Vista3D weights
  freeze_encoder: false  # Freeze encoder for fine-tuning

# =============================================================================
# Training Configuration
# =============================================================================
training:
  # Training mode:
  #   - 'auto': Automatic segmentation (standard training)
  #   - 'interactive': Point-prompt based training
  #   - 'mixed': Alternate between auto and interactive
  mode: auto
  
  # Number of point prompts for interactive/mixed mode
  num_point_prompts: 5
  
  # Training schedule
  max_epochs: 200
  
  # Hardware
  # Use CUDA_VISIBLE_DEVICES to select a free GPU:
  #   CUDA_VISIBLE_DEVICES=5 python scripts/train_vista3d.py --config configs/snemi3d_cremi3d.yaml
  accelerator: gpu
  devices: 1  # Use 1 GPU (selected by CUDA_VISIBLE_DEVICES)
  strategy: auto  # Will use SingleDeviceStrategy for 1 GPU
  
  # Mixed precision for memory efficiency
  precision: 16-mixed
  
  # Gradient settings
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  
  # Validation
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 2
  
  # Logging
  log_every_n_steps: 10
  
  # Performance
  benchmark: true
  deterministic: false
  
  # Development
  fast_dev_run: false

# =============================================================================
# Optimizer Configuration
# =============================================================================
optimizer:
  type: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-5
  betas: [0.9, 0.999]
  
  scheduler:
    type: cosine
    T_max: 200
    eta_min: 1.0e-7

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  # Semantic segmentation loss weights
  ce_weight: 0.5
  dice_weight: 0.5
  boundary_weight: 0.1  # Optional boundary-aware loss
  
  # Instance segmentation loss weight (discriminative loss)
  ins_weight: 1.0
  
  # Discriminative loss configuration (for instance embeddings)
  # Based on "Semantic Instance Segmentation with a Discriminative Loss Function"
  discriminative:
    delta_var: 0.5    # Margin for variance term (pull same instance together)
    delta_dist: 1.5   # Margin for distance term (push different instances apart)
    norm: 2           # L2 norm
    alpha: 1.0        # Weight for variance term
    beta: 1.0         # Weight for distance term
    gamma: 0.001      # Weight for regularization term
  
  # Class weights for imbalanced data (background, neuron, cleft, mito)
  # Higher weights for rarer classes
  class_weights: [0.1, 0.4, 0.3, 0.2]
  
  # Ignore index for unlabeled regions
  ignore_index: -100

# =============================================================================
# Callbacks Configuration
# =============================================================================
callbacks:
  checkpoint:
    enabled: true
    # Checkpoint directory is relative to log_dir/{experiment_name}/
    dirpath: null  # Will be set to {log_dir}/{experiment_name}/checkpoints
    # Can monitor val/dice (semantic), val/ari, or val/ami (instance metrics)
    filename: "vista3d-{epoch:02d}-{val/dice:.4f}-{val/ari:.4f}"
    save_top_k: 3
    monitor: val/dice  # Can also use val/ari for instance segmentation
    mode: max
    save_last: true
  
  early_stopping:
    enabled: true
    monitor: val/dice  # Can also use val/ari for instance segmentation
    patience: 50
    mode: max
  
  tensorboard_volume:
    enabled: true
    log_every_n_epochs: 1  # Log volume slices every N epochs
    num_slices: 4          # Number of slices to visualize (horizontal row)
    # For tensor [Z, Y, X] = [D, H, W]:
    # - "axial": slice through Z, view Y-X plane (typical EM microscope view)
    # - "coronal": slice through Y, view Z-X plane
    # - "sagittal": slice through X, view Z-Y plane
    # With patch_size [32, 128, 128], axial gives square [128, 128] slices
    slice_axes: ["axial"]  # Only YX plane (typical EM view)
    max_samples: 4         # Max samples to visualize per batch
    log_train: true        # Log training samples
    log_val: true          # Log validation samples
    log_embeddings: true   # Log instance embeddings as PCA projection to RGB
    log_instances: true    # Log clustered instance segmentation
    clustering_bandwidth: 0.5  # Bandwidth for mean-shift clustering

# =============================================================================
# Inference Configuration (for scripts/infer_vista3d.py)
# =============================================================================
inference:
  # Sliding window settings [Z, Y, X]
  patch_size: [32, 128, 128]
  stride: [16, 64, 64]  # 50% overlap
  aggregation: gaussian  # 'gaussian', 'average', 'max'
  batch_size: 4
